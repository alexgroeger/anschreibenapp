# üöÄ Deployment-Anleitung: Jetzt deployen (Verbesserte Version)

Diese Anleitung f√ºhrt Sie Schritt f√ºr Schritt durch das Deployment auf Google Cloud Run.
**WICHTIG**: Diese Version sucht automatisch nach dem Bucket mit vorhandenen Daten, um Datenverlust zu vermeiden!

## ‚úÖ Voraussetzungen erf√ºllt

- ‚úÖ Code kompiliert ohne Fehler
- ‚úÖ Docker Image erfolgreich gebaut
- ‚úÖ API-Endpoints getestet
- ‚úÖ Dokumentation vollst√§ndig
- ‚úÖ gcloud CLI installiert und im PATH
- ‚úÖ Google Cloud Projekt konfiguriert
- ‚úÖ API Key f√ºr Google Generative AI (optional, kann sp√§ter gesetzt werden)

## üìã Schnellstart (5 Minuten)

### Schritt 0: Environment Setup

```bash
# 1. gcloud PATH setzen (falls nicht im PATH)
export PATH="$HOME/google-cloud-sdk/bin:/usr/local/bin:$PATH"

# 2. Projekt-Konfiguration
export GCP_PROJECT_ID="gen-lang-client-0764998759"
export PROJECT_NUMBER="411832844870"
export GCP_REGION="europe-west1"
export SERVICE_NAME="anschreiben-app"

# 3. API Key setzen (falls vorhanden)
export GOOGLE_GENERATIVE_AI_API_KEY="ihr-api-key-hier"

# 4. Datenbankpfad setzen (optional - nur wenn Volume gemountet)
export DATABASE_PATH="/anschreiben-app/database.sqlite"  # F√ºr Cloud Run mit Volume
# export DATABASE_PATH="./data/anschreiben.db"  # F√ºr lokale Entwicklung
```

### Schritt 1: Google Cloud Setup

```bash
# 1. Projekt setzen
gcloud config set project $GCP_PROJECT_ID

# 2. APIs aktivieren
gcloud services enable cloudbuild.googleapis.com \
  run.googleapis.com \
  containerregistry.googleapis.com \
  storage.googleapis.com \
  --project=$GCP_PROJECT_ID
```

### Schritt 2: Cloud Storage Bucket pr√ºfen und verwenden

**WICHTIG**: Wir verwenden IMMER den festen Bucket-Namen `411832844870-anschreiben-data`. Es wird KEIN neuer Bucket erstellt!

```bash
# FESTER Bucket-Name (wird immer verwendet - dieser Bucket enth√§lt bereits alle Daten)
BUCKET_NAME="411832844870-anschreiben-data"

echo "=== Schritt 2: Pr√ºfe Cloud Storage Bucket ==="
echo "Fester Bucket-Name: $BUCKET_NAME"
echo ""

# Pr√ºfe ob Bucket existiert
if gcloud storage buckets describe "gs://$BUCKET_NAME" --project="$GCP_PROJECT_ID" &> /dev/null; then
  echo "‚úì Bucket existiert: $BUCKET_NAME"
  
  # Pr√ºfe auf Datenbank
  if gcloud storage ls "gs://$BUCKET_NAME/anschreiben.db" --project="$GCP_PROJECT_ID" &> /dev/null; then
    echo "‚úì Datenbank gefunden: anschreiben.db"
  else
    echo "‚ö† Datenbank nicht gefunden (wird beim ersten Start erstellt)"
  fi
  
  # Pr√ºfe auf Backup
  if gcloud storage ls "gs://$BUCKET_NAME/anschreiben_backup.db" --project="$GCP_PROJECT_ID" &> /dev/null; then
    echo "‚úì Backup gefunden: anschreiben_backup.db"
  fi
  
  # Pr√ºfe auf Dokumente
  DOC_COUNT=$(gcloud storage ls "gs://$BUCKET_NAME/application-documents/**" --project="$GCP_PROJECT_ID" 2>/dev/null | wc -l | tr -d ' ')
  if [ "$DOC_COUNT" -gt 0 ]; then
    echo "‚úì Dokumente gefunden: $DOC_COUNT Dateien in application-documents/"
  else
    echo "‚Ñπ Keine Dokumente gefunden (normal bei erstem Start)"
  fi
  
  JOB_DOC_COUNT=$(gcloud storage ls "gs://$BUCKET_NAME/job-documents/**" --project="$GCP_PROJECT_ID" 2>/dev/null | wc -l | tr -d ' ')
  if [ "$JOB_DOC_COUNT" -gt 0 ]; then
    echo "‚úì Job-Dokumente gefunden: $JOB_DOC_COUNT Dateien in job-documents/"
  fi
  
  # Pr√ºfe auf Prompts-Verzeichnis
  if gcloud storage ls "gs://$BUCKET_NAME/prompts/" --project="$GCP_PROJECT_ID" &> /dev/null; then
    echo "‚úì Prompts-Verzeichnis gefunden"
  fi

  echo ""
  echo "=== Bucket-Konfiguration ==="
  echo "Verwendeter Bucket: $BUCKET_NAME"
  echo ""
  echo "üìã Was wird in diesem Bucket gespeichert:"
  echo "  ‚úì Datenbank (anschreiben.db) - enth√§lt ALLE Daten:"
  echo "    - Bewerbungen (applications)"
  echo "    - Admin-Einstellungen (settings)"
  echo "    - Prompts (prompts, prompt_versions)"
  echo "    - Anschreiben-Versionen (cover_letter_versions)"
  echo "    - Dokument-Metadaten (application_documents)"
  echo "    - Erinnerungen (reminders)"
  echo "    - Kontaktpersonen (contact_persons)"
  echo "    - Lebenslauf (resume, resume_versions)"
  echo "    - Alte Anschreiben (old_cover_letters)"
  echo "  ‚úì Dokumente (application-documents/{id}/{filename})"
  echo "  ‚úì Job-Dokumente (job-documents/{filename})"
  echo ""
  echo "‚ö† WICHTIG: Dieser Bucket wird IMMER verwendet - kein neuer wird erstellt!"
  echo "BUCKET_NAME=$BUCKET_NAME"
else
  echo "‚ùå FEHLER: Bucket $BUCKET_NAME existiert nicht!"
  echo ""
  echo "Dieser Bucket sollte bereits existieren und alle Daten enthalten."
  echo "Bitte pr√ºfen Sie, ob der Bucket-Name korrekt ist oder kontaktieren Sie den Administrator."
  echo ""
  exit 1
fi
```

**Kritisch**: 
- Es wird KEIN neuer Bucket erstellt
- Wenn der Bucket nicht existiert, wird das Script mit Fehler beendet
- Der Bucket `411832844870-anschreiben-data` ist fest definiert und enth√§lt bereits alle Daten
- So wird garantiert immer der gleiche Bucket verwendet und keine Daten gehen verloren!

### Schritt 2.5: Volume Mount vs. Standard-Konfiguration

Die App unterst√ºtzt zwei Deployment-Modi:

#### Option A: Mit Cloud Storage Volume Mount (Empfohlen f√ºr direkten Zugriff)

**Vorteile:**
- ‚úÖ Direkter Dateisystem-Zugriff auf Cloud Storage
- ‚úÖ Datenbank wird direkt im gemounteten Volume gespeichert
- ‚úÖ Keine zus√§tzliche Synchronisation n√∂tig (direkter Zugriff)
- ‚úÖ Bessere Performance f√ºr h√§ufige Schreiboperationen

**Konfiguration:**
- Setzen Sie `DATABASE_PATH=/anschreiben-app/database.sqlite`
- Verwenden Sie `--add-volume` und `--add-volume-mount` beim Deployment
- Das Volume wird unter `/anschreiben-app` gemountet

**Wann verwenden:**
- Wenn Sie direkten Dateisystem-Zugriff auf Cloud Storage ben√∂tigen
- Wenn die Datenbank h√§ufig geschrieben wird
- Wenn Sie die Datenbank direkt im Bucket speichern m√∂chten

#### Option B: Ohne Volume Mount (Standard - Synchronisation √ºber API)

**Vorteile:**
- ‚úÖ Einfacheres Setup (keine Volume Mount Konfiguration)
- ‚úÖ Funktioniert zuverl√§ssig mit SQLite
- ‚úÖ Automatische Synchronisation zu/von Cloud Storage
- ‚úÖ Datenbank l√§uft lokal, wird nur synchronisiert

**Konfiguration:**
- Lassen Sie `DATABASE_PATH` ungesetzt (Standardpfad: `/app/data/anschreiben.db`)
- Keine Volume Mount Parameter beim Deployment
- Die App synchronisiert automatisch mit Cloud Storage

**Wann verwenden:**
- Standard-Deployment ohne spezielle Anforderungen
- Wenn Sie die Flexibilit√§t der API-basierten Synchronisation bevorzugen
- F√ºr einfacheres Setup und Wartung

**Empfehlung:** Verwenden Sie Option A (Volume Mount), wenn Sie bereits ein Volume gemountet haben. Die App pr√ºft beim Start automatisch, ob das Verzeichnis existiert und beschreibbar ist.

### Schritt 3: Docker Image bauen und pushen

```bash
# Image zu Google Container Registry pushen
cd "/Users/mac-join/Documents/Cursor/Repos/Anschreiben App"
gcloud builds submit --tag gcr.io/$GCP_PROJECT_ID/$SERVICE_NAME --project=$GCP_PROJECT_ID

# Oder mit bereitgestelltem Script
./cloud-run-deploy.sh
```

### Schritt 4: Cloud Run Service deployen

**WICHTIG**: Verwenden Sie den Bucket-Namen aus Schritt 2!

```bash
# WICHTIG: Verwenden Sie den Bucket, der in Schritt 2 gefunden wurde!
# Falls Sie in Schritt 2 einen anderen Bucket gefunden haben, verwenden Sie diesen!

# Environment-Variablen vorbereiten
# Verwende den Bucket, der in Schritt 2 gefunden wurde
ENV_VARS="GCS_BUCKET_NAME=$BUCKET_NAME"

# DATABASE_PATH hinzuf√ºgen (wenn Volume gemountet wird)
if [ -n "$DATABASE_PATH" ]; then
  ENV_VARS="$ENV_VARS,DATABASE_PATH=$DATABASE_PATH"
  echo "‚Ñπ DATABASE_PATH gesetzt: $DATABASE_PATH (Volume Mount wird verwendet)"
else
  # Standardpfad verwenden (kein Volume Mount)
  echo "‚Ñπ DATABASE_PATH nicht gesetzt - verwende Standardpfad /app/data/anschreiben.db"
fi

# API Key hinzuf√ºgen (falls gesetzt)
if [ -n "$GOOGLE_GENERATIVE_AI_API_KEY" ]; then
  ENV_VARS="$ENV_VARS,GOOGLE_GENERATIVE_AI_API_KEY=$GOOGLE_GENERATIVE_AI_API_KEY"
fi

echo "Deploye mit Bucket: $BUCKET_NAME"
echo "Environment-Variablen: $ENV_VARS"

# Service deployen mit Volume Mount (wenn DATABASE_PATH gesetzt)
if [ -n "$DATABASE_PATH" ]; then
  echo "Deploye mit Volume Mount..."
  gcloud run deploy $SERVICE_NAME \
    --image gcr.io/$GCP_PROJECT_ID/$SERVICE_NAME \
    --region $GCP_REGION \
    --platform managed \
    --allow-unauthenticated \
    --port 8080 \
    --memory 2Gi \
    --cpu 2 \
    --timeout 300 \
    --max-instances 10 \
    --set-env-vars $ENV_VARS \
    --add-volume name=gcs-1,type=cloud-storage,bucket=$BUCKET_NAME \
    --add-volume-mount volume=gcs-1,mount-path=/anschreiben-app \
    --project=$GCP_PROJECT_ID
else
  # Deployment ohne Volume Mount
  echo "Deploye ohne Volume Mount (Standard-Konfiguration)..."
  gcloud run deploy $SERVICE_NAME \
    --image gcr.io/$GCP_PROJECT_ID/$SERVICE_NAME \
    --region $GCP_REGION \
    --platform managed \
    --allow-unauthenticated \
    --port 8080 \
    --memory 2Gi \
    --cpu 2 \
    --timeout 300 \
    --max-instances 10 \
    --set-env-vars $ENV_VARS \
    --project=$GCP_PROJECT_ID
fi

# Nach dem Deployment: Pr√ºfen Sie die Logs
echo ""
echo "Warte 15 Sekunden, dann pr√ºfe Logs auf Datenbank-Download..."
sleep 15
gcloud run services logs read $SERVICE_NAME \
  --region $GCP_REGION \
  --limit 30 \
  --project=$GCP_PROJECT_ID | grep -E "(Database|Cloud Storage|anschreiben.db|download|upload|sync)"
```

**Erwartete Logs bei erfolgreichem Start:**
- `SQLite database path: /anschreiben-app/database.sqlite` (oder Standardpfad, falls kein Volume Mount)
- `Using Cloud Storage bucket: 411832844870-anschreiben-data`
- `Mount directory /anschreiben-app: exists=true, writable=true` (falls Volume Mount verwendet)
- `Database downloaded successfully from Cloud Storage` (falls Datenbank im Bucket vorhanden)
- `Cloud Storage is configured and ready for sync`

### Schritt 5: Service URL abrufen

```bash
SERVICE_URL=$(gcloud run services describe $SERVICE_NAME \
  --region $GCP_REGION \
  --format="value(status.url)" \
  --project=$GCP_PROJECT_ID)

echo "Service URL: $SERVICE_URL"
# Erwartete URL: https://anschreiben-app-411832844870.europe-west1.run.app
```

## üß™ Nach Deployment testen

### 1. App √∂ffnen
√ñffnen Sie die Service-URL im Browser.

### 2. Admin-Panel pr√ºfen
- Gehen Sie zu: `https://ihre-url/admin/database`
- Pr√ºfen Sie Cloud Storage Status
- Sollte "Konfiguriert" anzeigen
- **WICHTIG**: Pr√ºfen Sie, ob die Datenbank-Datei im Bucket vorhanden ist

### 3. API-Endpoint testen
```bash
# Status pr√ºfen
curl https://ihre-url/api/admin/database/sync

# Sollte zur√ºckgeben:
# {
#   "cloudStorageConfigured": true,
#   "bucketName": "411832844870-anschreiben-data",
#   ...
# }
```

### 4. Testdaten erstellen
- Erstellen Sie eine Test-Bewerbung
- Warten Sie 2-3 Sekunden
- Pr√ºfen Sie Cloud Storage: `gcloud storage ls gs://$BUCKET_NAME/ --project=$GCP_PROJECT_ID`

### 5. Neustart-Test
```bash
# Service neu starten
gcloud run services update $SERVICE_NAME \
  --region $GCP_REGION \
  --project=$GCP_PROJECT_ID

# Pr√ºfen Sie, ob Daten noch vorhanden sind
```

## üìä Erwartete Logs

Nach dem Deployment sollten Sie folgende Logs sehen:

```bash
gcloud run services logs read $SERVICE_NAME \
  --region $GCP_REGION \
  --limit 20 \
  --project=$GCP_PROJECT_ID
```

**Erwartete Meldungen beim Start:**
- `SQLite database path: <konfigurierter-pfad>` - Best√§tigt den verwendeten Datenbankpfad
- `Using Cloud Storage bucket: 411832844870-anschreiben-data` - Best√§tigt den verwendeten Bucket
- `Mount directory /anschreiben-app: exists=true, writable=true` - Best√§tigt, dass Volume Mount funktioniert (falls verwendet)
- `Cloud Storage is configured and ready for sync` - Cloud Storage ist bereit
- `Database downloaded successfully from Cloud Storage` - Datenbank wurde erfolgreich geladen (falls vorhanden)

**Erwartete Meldungen nach Schreiboperationen:**
- `Database uploaded successfully to Cloud Storage` - Datenbank wurde erfolgreich synchronisiert

## üîÑ Datenwiederherstellung nach Deployment

Falls nach dem Deployment Daten fehlen:

### 1. Pr√ºfen Sie, welcher Bucket die Daten enth√§lt

```bash
# Liste alle Buckets
gcloud storage buckets list --project=$GCP_PROJECT_ID

# Pr√ºfe jeden Bucket auf Datenbank-Datei
for BUCKET in $(gcloud storage buckets list --project=$GCP_PROJECT_ID --format="value(name)"); do
  echo "Pr√ºfe Bucket: $BUCKET"
  if gcloud storage ls "gs://$BUCKET/anschreiben.db" --project="$GCP_PROJECT_ID" &> /dev/null; then
    echo "  ‚úì Datenbank gefunden in: $BUCKET"
    echo "  Verwenden Sie diesen Bucket-Name f√ºr GCS_BUCKET_NAME"
  fi
done
```

### 2. Setzen Sie den korrekten Bucket-Namen

```bash
# Setze den Bucket-Namen, der die Daten enth√§lt
CORRECT_BUCKET="name-des-buckets-mit-daten"

gcloud run services update $SERVICE_NAME \
  --update-env-vars GCS_BUCKET_NAME=$CORRECT_BUCKET \
  --region $GCP_REGION \
  --project=$GCP_PROJECT_ID
```

### 3. Service neu starten

```bash
# Service neu starten, damit Datenbank geladen wird
gcloud run services update $SERVICE_NAME \
  --region $GCP_REGION \
  --project=$GCP_PROJECT_ID
```

### 4. Pr√ºfen Sie die Logs

```bash
gcloud run services logs read $SERVICE_NAME \
  --region $GCP_REGION \
  --limit 50 \
  --project=$GCP_PROJECT_ID | grep -E "(Database|Cloud Storage|download|upload)"
```

**Erwartete Logs bei erfolgreicher Wiederherstellung:**
- `Database downloaded successfully from Cloud Storage`
- `Cloud Storage is configured and ready for sync`

## üîß Troubleshooting

### Problem: "Cloud Storage not configured"
**L√∂sung**: Pr√ºfen Sie Environment-Variable:
```bash
gcloud run services describe $SERVICE_NAME \
  --region $GCP_REGION \
  --format="value(spec.template.spec.containers[0].env)" \
  --project=$GCP_PROJECT_ID
```

### Problem: "Permission denied"
**L√∂sung**: Service Account Berechtigungen pr√ºfen:
```bash
# Berechtigungen setzen
gcloud projects add-iam-policy-binding $GCP_PROJECT_ID \
  --member="serviceAccount:${PROJECT_NUMBER}-compute@developer.gserviceaccount.com" \
  --role="roles/storage.objectAdmin" \
  --project=$GCP_PROJECT_ID
```

### Problem: Daten gehen verloren
**L√∂sung**: 
1. Pr√ºfen Sie, welcher Bucket die Daten enth√§lt (siehe Sektion "Datenwiederherstellung")
2. Setzen Sie den korrekten Bucket-Namen in Cloud Run
3. Logs pr√ºfen auf Sync-Fehler
4. Bucket pr√ºfen: `gcloud storage ls gs://$BUCKET_NAME/ --project=$GCP_PROJECT_ID`
5. Manuelle Synchronisation testen √ºber Admin-Panel

### Problem: "Mount directory /anschreiben-app does not exist"
**L√∂sung**: 
1. Stellen Sie sicher, dass das Volume korrekt gemountet ist:
   ```bash
   gcloud run services describe $SERVICE_NAME \
     --region $GCP_REGION \
     --format="yaml(spec.template.spec.volumes,spec.template.spec.containers[0].volumeMounts)" \
     --project=$GCP_PROJECT_ID
   ```
2. Pr√ºfen Sie, ob `--add-volume` und `--add-volume-mount` im Deployment-Befehl enthalten sind
3. Falls kein Volume Mount verwendet wird, entfernen Sie `DATABASE_PATH` oder setzen Sie es auf den Standardpfad
4. Service neu deployen mit korrekter Volume Mount Konfiguration

### Problem: "Mount directory /anschreiben-app exists but is not writable"
**L√∂sung**: 
1. Pr√ºfen Sie die Berechtigungen des gemounteten Volumes:
   ```bash
   gcloud run services describe $SERVICE_NAME \
     --region $GCP_REGION \
     --format="value(spec.template.spec.volumes[0].csi.driver)" \
     --project=$GCP_PROJECT_ID
   ```
2. Stellen Sie sicher, dass der Service Account Schreibrechte hat:
   ```bash
   gcloud projects add-iam-policy-binding $GCP_PROJECT_ID \
     --member="serviceAccount:${PROJECT_NUMBER}-compute@developer.gserviceaccount.com" \
     --role="roles/storage.objectAdmin" \
     --project=$GCP_PROJECT_ID
   ```
3. Pr√ºfen Sie die Cloud Storage Bucket-Berechtigungen
4. Service neu starten nach Berechtigungs√§nderungen

### Problem: "SQLite database path" Log zeigt falschen Pfad
**L√∂sung**: 
1. Pr√ºfen Sie die Logs: `gcloud run services logs read $SERVICE_NAME --region $GCP_REGION | grep "SQLite database path"`
2. Stellen Sie sicher, dass `DATABASE_PATH` korrekt gesetzt ist (ohne Leerzeichen, vollst√§ndiger Pfad):
   ```bash
   gcloud run services describe $SERVICE_NAME \
     --region $GCP_REGION \
     --format="value(spec.template.spec.containers[0].env[?(@.name=='DATABASE_PATH')].value)" \
     --project=$GCP_PROJECT_ID
   ```
3. Falls der Pfad falsch ist, aktualisieren Sie die Environment-Variable:
   ```bash
   gcloud run services update $SERVICE_NAME \
     --update-env-vars DATABASE_PATH=/anschreiben-app/database.sqlite \
     --region $GCP_REGION \
     --project=$GCP_PROJECT_ID
   ```
4. Service neu starten

## üìù Checkliste

- [ ] Google Cloud Projekt erstellt
- [ ] APIs aktiviert
- [ ] Cloud Storage Bucket mit Daten gefunden
- [ ] Korrekter Bucket-Name notiert
- [ ] Docker Image gebaut und gepusht
- [ ] Cloud Run Service deployed mit korrektem Bucket-Namen
- [ ] `DATABASE_PATH` Environment-Variable gesetzt (falls Volume gemountet)
- [ ] Volume Mount korrekt konfiguriert (`--add-volume` und `--add-volume-mount`, falls verwendet)
- [ ] Environment-Variablen gesetzt (GCS_BUCKET_NAME, GOOGLE_GENERATIVE_AI_API_KEY, DATABASE_PATH)
- [ ] Service URL notiert
- [ ] Logs gepr√ºft auf "SQLite database path" (best√§tigt korrekten Pfad)
- [ ] Logs gepr√ºft auf "Using Cloud Storage bucket" (best√§tigt Bucket-Name)
- [ ] Logs gepr√ºft auf "Mount directory /anschreiben-app: exists=true, writable=true" (falls Volume Mount verwendet)
- [ ] Logs gepr√ºft auf "Database downloaded successfully"
- [ ] Admin-Panel getestet
- [ ] API-Endpoints getestet
- [ ] Testdaten erstellt
- [ ] Cloud Storage Synchronisation gepr√ºft
- [ ] Neustart-Test durchgef√ºhrt
- [ ] Daten bleiben nach Neustart erhalten

## üéØ Erfolgskriterien

Deployment ist erfolgreich, wenn:
- ‚úÖ App l√§uft auf Cloud Run
- ‚úÖ Admin-Panel zeigt "Cloud Storage konfiguriert"
- ‚úÖ API-Endpoint `/api/admin/database/sync` gibt `cloudStorageConfigured: true` zur√ºck
- ‚úÖ Logs zeigen korrekten "SQLite database path" (best√§tigt verwendeten Pfad)
- ‚úÖ Logs zeigen "Using Cloud Storage bucket: 411832844870-anschreiben-data" (best√§tigt Bucket-Name)
- ‚úÖ Logs zeigen "Mount directory /anschreiben-app: exists=true, writable=true" (falls Volume Mount verwendet)
- ‚úÖ Logs zeigen "Database downloaded successfully from Cloud Storage" (falls Datenbank vorhanden)
- ‚úÖ Mount-Verzeichnis ist beschreibbar (falls Volume Mount verwendet)
- ‚úÖ Startup-Logging best√§tigt alle Konfigurationen
- ‚úÖ Testdaten werden zu Cloud Storage synchronisiert
- ‚úÖ Daten bleiben nach Neustart erhalten

## üìö Weitere Dokumentation

- **Detaillierte Checkliste**: [DEPLOYMENT_CHECKLIST.md](./DEPLOYMENT_CHECKLIST.md)
- **Setup-Anleitung**: [CLOUD_STORAGE_SETUP.md](./CLOUD_STORAGE_SETUP.md)
- **Testing-Guide**: [TESTING_GUIDE.md](./TESTING_GUIDE.md)
- **Deployment-Guide**: [DEPLOYMENT.md](./DEPLOYMENT.md)

## üéâ Fertig!

Nach erfolgreichem Deployment haben Sie:
- ‚úÖ Persistente Datenbank-Speicherung
- ‚úÖ Automatische Synchronisation
- ‚úÖ Backup-Strategie
- ‚úÖ Skalierbare L√∂sung
- ‚úÖ Keine Datenverluste mehr!

**Viel Erfolg beim Deployment!** üöÄ

## üöÄ Vollst√§ndiges Deployment-Script (Alles in einem)

F√ºr ein schnelles Deployment k√∂nnen Sie alle Schritte in einem Script ausf√ºhren:

```bash
#!/bin/bash
set -e

# Environment Setup
export PATH="$HOME/google-cloud-sdk/bin:/usr/local/bin:$PATH"
export GCP_PROJECT_ID="gen-lang-client-0764998759"
export PROJECT_NUMBER="411832844870"
export GCP_REGION="europe-west1"
export SERVICE_NAME="anschreiben-app"

# API Key setzen (optional - kann auch sp√§ter gesetzt werden)
# export GOOGLE_GENERATIVE_AI_API_KEY="ihr-api-key-hier"

# Datenbankpfad setzen (optional - nur wenn Volume gemountet)
# export DATABASE_PATH="/anschreiben-app/database.sqlite"  # F√ºr Cloud Run mit Volume

echo "=== Schritt 1: Projekt setzen ==="
gcloud config set project $GCP_PROJECT_ID

echo "=== Schritt 2: APIs aktivieren ==="
gcloud services enable cloudbuild.googleapis.com \
  run.googleapis.com \
  containerregistry.googleapis.com \
  storage.googleapis.com \
  --project=$GCP_PROJECT_ID

echo "=== Schritt 3: Cloud Storage Bucket pr√ºfen ==="
# FESTER Bucket-Name (wird immer verwendet - dieser Bucket enth√§lt bereits alle Daten)
BUCKET_NAME="411832844870-anschreiben-data"

echo "Fester Bucket-Name: $BUCKET_NAME"

# Pr√ºfe ob Bucket existiert
if gcloud storage buckets describe "gs://$BUCKET_NAME" --project="$GCP_PROJECT_ID" &> /dev/null; then
  echo "‚úì Bucket existiert: $BUCKET_NAME"
  if gcloud storage ls "gs://$BUCKET_NAME/anschreiben.db" --project="$GCP_PROJECT_ID" &> /dev/null; then
    echo "‚úì Datenbank gefunden"
  fi
else
  echo "‚ùå FEHLER: Bucket $BUCKET_NAME existiert nicht!"
  echo "Dieser Bucket sollte bereits existieren und alle Daten enthalten."
  exit 1
fi

echo "=== Schritt 4: Docker Image bauen und pushen ==="
cd "$(dirname "$0")"
gcloud builds submit --tag gcr.io/$GCP_PROJECT_ID/$SERVICE_NAME --project=$GCP_PROJECT_ID

echo "=== Schritt 5: Cloud Run Service deployen ==="
ENV_VARS="GCS_BUCKET_NAME=$BUCKET_NAME"

# DATABASE_PATH hinzuf√ºgen (wenn Volume gemountet wird)
if [ -n "$DATABASE_PATH" ]; then
  ENV_VARS="$ENV_VARS,DATABASE_PATH=$DATABASE_PATH"
  echo "‚Ñπ DATABASE_PATH gesetzt: $DATABASE_PATH (Volume Mount wird verwendet)"
else
  echo "‚Ñπ DATABASE_PATH nicht gesetzt - verwende Standardpfad /app/data/anschreiben.db"
fi

# API Key hinzuf√ºgen (falls gesetzt)
if [ -n "$GOOGLE_GENERATIVE_AI_API_KEY" ]; then
  ENV_VARS="$ENV_VARS,GOOGLE_GENERATIVE_AI_API_KEY=$GOOGLE_GENERATIVE_AI_API_KEY"
fi

echo "Deploye mit Bucket: $BUCKET_NAME"
echo "Environment-Variablen: $ENV_VARS"

# Service deployen mit Volume Mount (wenn DATABASE_PATH gesetzt)
if [ -n "$DATABASE_PATH" ]; then
  echo "Deploye mit Volume Mount..."
  gcloud run deploy $SERVICE_NAME \
    --image gcr.io/$GCP_PROJECT_ID/$SERVICE_NAME \
    --region $GCP_REGION \
    --platform managed \
    --allow-unauthenticated \
    --port 8080 \
    --memory 2Gi \
    --cpu 2 \
    --timeout 300 \
    --max-instances 10 \
    --set-env-vars $ENV_VARS \
    --add-volume name=gcs-1,type=cloud-storage,bucket=$BUCKET_NAME \
    --add-volume-mount volume=gcs-1,mount-path=/anschreiben-app \
    --project=$GCP_PROJECT_ID
else
  # Deployment ohne Volume Mount
  echo "Deploye ohne Volume Mount (Standard-Konfiguration)..."
  gcloud run deploy $SERVICE_NAME \
    --image gcr.io/$GCP_PROJECT_ID/$SERVICE_NAME \
    --region $GCP_REGION \
    --platform managed \
    --allow-unauthenticated \
    --port 8080 \
    --memory 2Gi \
    --cpu 2 \
    --timeout 300 \
    --max-instances 10 \
    --set-env-vars $ENV_VARS \
    --project=$GCP_PROJECT_ID
fi

echo "=== Schritt 6: Service URL abrufen ==="
SERVICE_URL=$(gcloud run services describe $SERVICE_NAME \
  --region $GCP_REGION \
  --format="value(status.url)" \
  --project=$GCP_PROJECT_ID)

echo ""
echo "‚úÖ Deployment erfolgreich!"
echo "Service URL: $SERVICE_URL"
echo "Verwendeter Bucket: $BUCKET_NAME"
echo ""
echo "Pr√ºfe Logs auf Datenbank-Download..."
sleep 15
gcloud run services logs read $SERVICE_NAME \
  --region $GCP_REGION \
  --limit 30 \
  --project=$GCP_PROJECT_ID | grep -E "(SQLite database path|Using Cloud Storage bucket|Mount directory|Database|Cloud Storage|anschreiben.db|download|upload|sync)" || echo "Keine relevanten Logs gefunden"
echo ""
echo "Falls der API Key noch nicht gesetzt wurde:"
echo "gcloud run services update $SERVICE_NAME \\"
echo "  --update-env-vars GOOGLE_GENERATIVE_AI_API_KEY=\"ihr-api-key\" \\"
echo "  --region $GCP_REGION \\"
echo "  --project=$GCP_PROJECT_ID"
```

